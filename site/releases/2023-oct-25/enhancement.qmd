---
title: "Enhancements -- October 25, 2023"
keywords: "release notes, model risk management, ValidMind"
---

<!---[SC-2411] Clustering models support by @AnilSorathiya in [#271](https://github.com/validmind/developer-framework/pull/271)--->
- **[SC-2411] Clustering models support**. This PR add support to clustering models in the framework. The PR covers the following:
* A quickstart demo notebook for a simple clustering model. 
* A standard digits dataset has been used to create a demo.
* New metrics have been added  to the developer framework to have decent support for clustering models.

<!---John6797/sc 2416/embeddings models support by @johnwalz97 in [#272](https://github.com/validmind/developer-framework/pull/272)--->
- **Embeddings models support**. We added initial support for text embeddings models in the ValidMind Developer Framework. This support provides the ability to create, use and test a BERT embeddings model using the Hugging Face library. Changes include:
   
   - Added a new folder in `model_validation` tests for embeddings, along with initial versions of tests for text embedding models.
   - Introduced support for `feature_extraction` tasks in the Hugging Face model wrapper within the ValidMind Developer Framework, enabling embedding extraction from a Hugging Face model.
   - Added a new internal notebook to demonstrate these features and updated related dependencies.
   
   **Note**: The notebook demonstrating these features is not currently available externally.

<!---[SC-2346] Rouge and Bert score metrics should show average scores by @juanmleng in [#263](https://github.com/validmind/developer-framework/pull/263)--->
- **Rouge and Bert Score metrics now show average scores**: Introduced `RougeMetricsAggregate` and `BertScoreAggregate` to offer a high-level overview of model performance across a large number of text rows. These metrics complement the detailed row-by-row analysis provided by `RougeMetrics` and `BertScore`.
<!--- NR this notebook is not currently included in our docs site:
Tested these metrics running `foundational_models_summarization_high_code.ipynb` --->

<!---[SC-2143] Metrics for safety toxicity and bias in text summarization by @juanmleng in [#258](https://github.com/validmind/developer-framework/pull/258)--->
- **Added metrics for safety toxicity and bias in text summarization**. We introduced several new metrics to evaluate safety and bias risks in text summarization:
   
   - `ToxicityScore`: Measures safety risk
   - `ToxicityHistogram`: Provides a distribution of safety risk scores
   - `RegardScore`: Evaluates bias risk
   - `RegardHistogram`: Shows distribution of bias risk scores
<!--- NR this notebook is not currently included in our docs site:
To test these metrics, see notebook `foundation_models_summarization_bias.ipynb`---> 