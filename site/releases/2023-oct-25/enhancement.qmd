---
title: "Enhancements -- October 25, 2023"
keywords: "release notes, model risk management, ValidMind"
---

<!---[SC-2411] Clustering models support by @AnilSorathiya in [#271](https://github.com/validmind/developer-framework/pull/271)--->
- **[SC-2411] Clustering models support**. This PR add support to clustering models in the framework. The PR covers the following:
* A quickstart demo notebook for a simple clustering model. 
* A standard digits dataset has been used to create a demo.
* New metrics have been added  to the developer framework to have decent support for clustering models.

<!---John6797/sc 2416/embeddings models support by @johnwalz97 in [#272](https://github.com/validmind/developer-framework/pull/272)--->
- **John6797/sc 2416/embeddings models support**. This PR adds initial support for text embeddings models in the developer framework. Specifically, we are adding a new notebook that demonstrates creating, using and testing a BERT embeddings model using the hugging face library.

Changes:
* adds new folder in model_validation tests for embeddings... adds initial versions of new tests for text embedding models
* adds support for `feature_extraction` tasks in the hugging face model wrapper in the dev framework so that we can extract embeddings from a hugging face model
* add new notebook for demonstrating the above
* updates dependencies

<!---[SC-2346] Rouge and Bert score metrics should show average scores by @juanmleng in [#263](https://github.com/validmind/developer-framework/pull/263)--->
- **Rouge and Bert score metrics should show average scores**. - Added `RougeMetricsAggregate` and `BertScoreAggregate` to provide a higher-level overview of model performance for high number of text rows. These metrics complement the detailed row-by-row analysis cover by `RougeMetrics` and `BertScore`.

- **Rouge and Bert Score Metrics Now Show Average Scores**: Introduced `RougeMetricsAggregate` and `BertScoreAggregate` to offer a high-level overview of model performance across a large number of text rows. These metrics complement the detailed row-by-row analysis provided by `RougeMetrics` and `BertScore`.

<!--- NR this notebook is not currently included in our docs site:
Tested these metrics running `foundational_models_summarization_high_code.ipynb` --->

<!---[SC-2143] Metrics for safety toxicity and bias in text summarization by @juanmleng in [#258](https://github.com/validmind/developer-framework/pull/258)--->
- **Added metrics for safety toxicity and bias in text summarization**. We introduced several new metrics to evaluate safety and bias risks in text summarization:
   
   - `ToxicityScore`: Measures safety risk
   - `ToxicityHistogram`: Provides a distribution of safety risk scores
   - `RegardScore`: Evaluates bias risk
   - `RegardHistogram`: Shows distribution of bias risk scores

<!--- NR this notebook is not currently included in our docs site:
To test these metrics, see notebook `foundation_models_summarization_bias.ipynb`---> 